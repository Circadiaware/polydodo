{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep stages classification pipeline\n",
    "___\n",
    "\n",
    "This notebooks aims to construct our feature matrix from our sleep records [sleep-edf](https://physionet.org/content/sleep-edfx/1.0.0/) from _physionet_. \n",
    "\n",
    "We will reuse the chosen features from our exploration notebook.\n",
    "\n",
    "Since all of the dataset cannot be loaded in memory at the same time, we will have to implement a pipeline, where each step can then be run with only one recording at a time. At the end of this notebook, we will be able to concatenate all resulting features in a single matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import (FunctionTransformer, StandardScaler)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import (train_test_split, KFold)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             classification_report,\n",
    "                             f1_score,\n",
    "                             cohen_kappa_score)\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import psd_welch\n",
    "\n",
    "from scipy.stats import (skew, kurtosis)\n",
    "from scipy.signal import butter\n",
    "\n",
    "from utils import fetch_data\n",
    "from constants import (SLEEP_STAGES_VALUES,\n",
    "                       DATASET_SLEEP_STAGES_VALUES,\n",
    "                       N_STAGES,\n",
    "                       EEG_CHANNELS, \n",
    "                       EPOCH_DURATION,\n",
    "                       SAMPLING_FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a few constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS_AWAKE_MORNING = 60\n",
    "    \n",
    "NYQUIST_FREQ = SAMPLING_FREQ/2\n",
    "MAX_TIME = EPOCH_DURATION - 1. / SAMPLING_FREQ  # tmax in included\n",
    "\n",
    "# EEG sub bands labels\n",
    "DELTA = \"delta\"\n",
    "THETA = \"theta\"\n",
    "ALPHA = \"alpha\"\n",
    "SIGMA = \"sigma\"\n",
    "BETA = \"beta\"\n",
    "\n",
    "FREQ_BANDS_RANGE = {\n",
    "    DELTA: [0.5, 4.5],\n",
    "    THETA: [4.5, 8.5],\n",
    "    ALPHA: [8.5, 11.5],\n",
    "    SIGMA: [11.5, 15.5],\n",
    "    BETA: [15.5, 30]\n",
    "}\n",
    "\n",
    "FREQ_BANDS_ORDERS = {\n",
    "    DELTA: 5,\n",
    "    THETA: 8,\n",
    "    ALPHA: 9,\n",
    "    SIGMA: 9,\n",
    "    BETA: 14\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "___\n",
    "\n",
    "Our dataset consists of 39 recordings, each containing about 20 hours of EEG, EOG, EMG, and other signals, sampled at 100 or 1Hz.\n",
    "\n",
    "### 1. Loading recordings informations\n",
    "___\n",
    "\n",
    "This file contains information about when a recording was started, at which time the subject went to bed and the amount of sleep he got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_records = pd.read_csv(\"data/recordings-info.csv\")\n",
    "df_records.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a new column where we indicate in which age group each subject belongs. They are arbitrarily chosen according to the histogram in order to have the relatively same number of observations among those groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_records['age'], bins=20)\n",
    "plt.show()\n",
    "\n",
    "age_groups = [\n",
    "    [0,49],  # 39 recordings\n",
    "    [50,59], # 41 recordings\n",
    "    [60,84], # 41 recordings\n",
    "    [85,110] # 32 recordings\n",
    "]\n",
    "\n",
    "df_records['AgeCategory'] = [None]*len(df_records)\n",
    "for index, group in enumerate(age_groups):\n",
    "    df_records.loc[(df_records['age'] >= group[0]) & (df_records['age'] <= group[1]), 'AgeCategory'] = index\n",
    "    \n",
    "df_records.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Retrieve data from file and filter to only one channel of EEG\n",
    "___\n",
    "\n",
    "This step includes:\n",
    "- Retrieving edf file\n",
    "- Excluding channels that are not EEG signals\n",
    "- Retrieving dataframe recordings information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_signal(psg_file_name, hypno_file_name):\n",
    "    \"\"\"\n",
    "    returns: mne.Raw of the whole night recording\n",
    "    \"\"\"\n",
    "    raw_data = mne.io.read_raw_edf(psg_file_name, preload=True, stim_channel=None, verbose=False)\n",
    "    annot = mne.read_annotations(hypno_file_name)\n",
    "    raw_data.set_annotations(annot, emit_warning=False)\n",
    "    \n",
    "    return raw_data\n",
    "\n",
    "def drop_other_channels(raw_data, channel_to_keep):\n",
    "    \"\"\"\n",
    "    returns: mne.Raw with the two EEG channels and the signal\n",
    "        between the time the subject closed the lights and the time\n",
    "        at which the subject woke up\n",
    "    \"\"\"\n",
    "    raw_data.drop_channels([ch for ch in raw_data.info['ch_names'] if ch != channel_to_keep])\n",
    "    \n",
    "    return raw_data\n",
    "\n",
    "def get_recording_info(file_name):\n",
    "    # Each file is named according to this pattern:\n",
    "    #   SC4ssNEO-PSG.edf where SS is subject index (3:5) and N is subject night index (5:6)\n",
    "    subject_index = int(file_name[3:5])\n",
    "    subject_night = int(file_name[5:6])\n",
    "    \n",
    "    return df_records[(df_records['subject'] == subject_index) & (df_records['night'] == subject_night)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recording_info(\"SC4121E0-PSG.edf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert Raw signal to epochs or matrices\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_epochs(raw_data, info):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        mne.Epochs, where the epochs are only choosen if the subject was in bed.\n",
    "        y: np array of shape (nb_epochs,), which contains each epoch label.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of seconds since file began\n",
    "    closed_lights_time = info['LightsOffSecond'].values[0]\n",
    "    woke_up_time = closed_lights_time + info['NightDuration'].values[0] + NB_EPOCHS_AWAKE_MORNING*EPOCH_DURATION\n",
    "\n",
    "    raw_data.crop(tmin=closed_lights_time, tmax=min(woke_up_time, raw_data.times[-1]))\n",
    "    \n",
    "    events, annot_event_id = mne.events_from_annotations(\n",
    "        raw_data,\n",
    "        event_id=DATASET_SLEEP_STAGES_VALUES,\n",
    "        chunk_duration=EPOCH_DURATION,\n",
    "        verbose=False)\n",
    "    \n",
    "    # Few files do not have N3 sleep (i.e. SC4202EC-Hypnogram), so we have to filter out key-value pairs that are not in the annotations.\n",
    "    event_id = { \n",
    "        event_key: SLEEP_STAGES_VALUES[event_key] \n",
    "        for event_key in SLEEP_STAGES_VALUES\n",
    "        if SLEEP_STAGES_VALUES[event_key] in annot_event_id.values()\n",
    "    }\n",
    "    \n",
    "    epochs = mne.Epochs(\n",
    "        raw=raw_data,\n",
    "        events=events,\n",
    "        event_id=event_id,\n",
    "        tmin=0.,\n",
    "        tmax=MAX_TIME,\n",
    "        preload=True,\n",
    "        baseline=None,\n",
    "        verbose=False)\n",
    "    \n",
    "    y = np.array([event[-1] for event in epochs.events])\n",
    "    \n",
    "    return epochs, y \n",
    "\n",
    "\n",
    "def convert_to_matrices(data):\n",
    "    \"\"\"\n",
    "    data: mne.Epochs with only one EEG channel\n",
    "    \n",
    "    returns\n",
    "        - X: Matrix of input values, of size (nb_epochs, sampling_rate*epoch_length=3000)\n",
    "        - y: Vector of observation labels, of size (nb_epochs,)\n",
    "    \"\"\"\n",
    "    df = data.to_data_frame(picks=\"eeg\", long_format=True)\n",
    "    df = df.drop(columns=['ch_type', 'channel'])\n",
    "    df = df.sort_values(by=['epoch', 'time'])\n",
    "    \n",
    "    y = df[['epoch', 'condition']].drop_duplicates(keep=\"first\")['condition'].to_numpy()\n",
    "    X = np.matrix(\n",
    "        [df[df['epoch'] == epoch]['observation'].to_numpy() for epoch in df['epoch'].unique()]\n",
    "    )\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete function to apply in order to preprocess our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, current_channel, df_info, convert_to_matrix=False):\n",
    "    \"\"\"\n",
    "    data: mne.Raw \n",
    "        Instance of all of the night recording and all channels\n",
    "    current_channel: str \n",
    "        Current EEG channel\n",
    "        \n",
    "    returns\n",
    "        - X: Matrix of input values, of size (nb_epochs, sampling_rate*epoch_length=3000)\n",
    "        - y: Vector of observation labels, of size (nb_epochs,)\n",
    "    \"\"\"\n",
    "    data = drop_other_channels(data, current_channel)\n",
    "    data, y = convert_to_epochs(data, df_info)\n",
    "    \n",
    "    if not convert_to_matrix:\n",
    "        return data, y\n",
    "    \n",
    "    return convert_to_matrices(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "___\n",
    "\n",
    "\n",
    "```\n",
    "        Frequency domain\n",
    "        features                +----> Average delta band +-+\n",
    "                +-------+       |                           |\n",
    "      +-------->+  FFT  +-------+      ...                  |\n",
    "      |         +-------+       |                           |\n",
    "      |                         +----> Mean frequency  +----+\n",
    "      |                                                     |\n",
    "      |                                                     |\n",
    "      |                                                     |\n",
    "  X +-+                                                     +-> X'\n",
    "Input |                                                     |   Features\n",
    "mne.  |                         +-----> Variance +----------+   np.array\n",
    "Epochs|                         |                           |   shape:\n",
    "      |         +----------+    |                           |    (nb_epochs, nb_features)\n",
    "      +-------->+ get_data +-------------> Mean +-----------+\n",
    "                +----------+    |                           |\n",
    "                                |       ...                 |\n",
    "                                |                           |\n",
    "                                +-----> Zero cross rate ----+\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "        Time\n",
    "        domain features\n",
    "\n",
    "```\n",
    "\n",
    "We first have to define a transformer that will extract the values out of an epoch instance. \n",
    "\n",
    "The pipeline **cannot fit** to the data it receives, because there will be several call to transform the input data, hence the epochs,  into the feature array. They will be transformed one night recording at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_epochs(epochs):\n",
    "    \"\"\"\n",
    "    epochs: mne.Epochs\n",
    "    \n",
    "    returns np array of shape (nb_epochs, sampling_rate*epoch_length)\n",
    "    \"\"\"\n",
    "    return epochs.get_data().squeeze()\n",
    "\n",
    "get_data_from_epochs_transformer = FunctionTransformer(get_data_from_epochs, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a skeleton fonction which receives a fonction that is called for every epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer(get_feature):\n",
    "    \n",
    "    def get_one_feature_per_epoch(X, get_feature):\n",
    "        \"\"\"\n",
    "        X: Input matrix (nb_epochs, sampling_rate*epoch_length)\n",
    "        get_feature: callable \n",
    "            generates one feature for each epoch\n",
    "\n",
    "        returns matrix (nb_epoch,1)\n",
    "        \"\"\"\n",
    "        return [[get_feature(epoch)] for epoch in X]\n",
    "\n",
    "    return lambda X: get_one_feature_per_epoch(X, get_feature)\n",
    "\n",
    "def get_transformer_list(get_features):\n",
    "    \n",
    "    def get_feature_list_per_epoch(X, get_features):\n",
    "        \"\"\"\n",
    "        X: Input matrix (nb_epochs, sampling_rate*epoch_length)\n",
    "        get_feature: callable \n",
    "            generates a list of features for each epoch\n",
    "\n",
    "        returns matrix (nb_epoch,nb_features)\n",
    "        \"\"\"\n",
    "        return [get_features(epoch) for epoch in X]\n",
    "\n",
    "    return lambda X: get_feature_list_per_epoch(X, get_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Time domain features\n",
    "___\n",
    "\n",
    "##### a) Standard statistics\n",
    "____\n",
    "\n",
    "We extract features on the distribution of the time domain values of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_transformer = FunctionTransformer(get_transformer(np.mean), validate=True)\n",
    "std_transformer = FunctionTransformer(get_transformer(np.std), validate=True)\n",
    "skew_transformer = FunctionTransformer(get_transformer(skew), validate=True)\n",
    "kurtosis_transformer = FunctionTransformer(get_transformer(kurtosis), validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Mean crossing rate\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing_rate(signal):\n",
    "    \"\"\"\n",
    "    Multiplies signal by itself shifted by one.\n",
    "    If the signal crosses the horizontal axis, the sign will be negative and vice-versa.\n",
    "    \n",
    "    Returns nb of time the signal crossed the horizontal axis\n",
    "    \"\"\"\n",
    "    return ((signal[:-1] * signal[1:]) < 0).sum()\n",
    "\n",
    "def get_mean_crossing_rate(signal):\n",
    "    return get_zero_crossing_rate(signal - np.mean(signal))\n",
    "\n",
    "mean_crossing_rate_transformer = FunctionTransformer(get_transformer(get_mean_crossing_rate), validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Hjorth parameters\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from PyEEG: https://github.com/forrestbao/pyeeg\n",
    "\n",
    "def hjorth(X):\n",
    "    \"\"\" Compute Hjorth mobility and complexity of a time series from either two\n",
    "    cases below:\n",
    "        1. X, the time series of type list (default)\n",
    "        2. D, a first order differential sequence of X (if D is provided,\n",
    "           recommended to speed up)\n",
    "    In case 1, D is computed using Numpy's Difference function.\n",
    "    Notes\n",
    "    -----\n",
    "    To speed up, it is recommended to compute D before calling this function\n",
    "    because D may also be used by other functions whereas computing it here\n",
    "    again will slow down.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        list\n",
    "        a time series\n",
    "    D\n",
    "        list\n",
    "        first order differential sequence of a time series\n",
    "    Returns\n",
    "    -------\n",
    "    As indicated in return line (mobility, complexity)\n",
    "    \"\"\"\n",
    "    D = np.diff(X)\n",
    "    D = D.tolist()\n",
    "\n",
    "    D.insert(0, X[0])  # pad the first difference\n",
    "    D = np.array(D)\n",
    "\n",
    "    n = len(X)\n",
    "\n",
    "    M2 = float(sum(D ** 2)) / n\n",
    "    TP = sum(np.array(X) ** 2)\n",
    "    M4 = 0\n",
    "    for i in range(1, len(D)):\n",
    "        M4 += (D[i] - D[i - 1]) ** 2\n",
    "    M4 = M4 / n\n",
    "\n",
    "    # Hjorth Mobility and Complexity\n",
    "    mobility = np.sqrt(M2 / TP)\n",
    "    complexity = np.sqrt(\n",
    "        float(M4) * TP / M2 / M2\n",
    "    )\n",
    "    return [mobility, complexity] # np.concatenate([mobility, complexity], axis=1)\n",
    "\n",
    "hjorth_transformer = FunctionTransformer(get_transformer_list(hjorth), validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging all time domain features with `FeatureUnion`\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_TIME_DOMAIN_FEATURES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain_feature_union = FeatureUnion([\n",
    "    ('mean', mean_transformer),\n",
    "    ('std', std_transformer),\n",
    "    ('skew', skew_transformer),\n",
    "    ('kurtosis', kurtosis_transformer),\n",
    "    ('mean-crossing-rate', mean_crossing_rate_transformer),\n",
    "    ('hjorth', hjorth_transformer)\n",
    "], n_jobs=1)\n",
    "\n",
    "time_domain_pipeline = Pipeline([\n",
    "    ('epochs_to_data', get_data_from_epochs_transformer),\n",
    "    ('time_domain_features', time_domain_feature_union)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Frequency domain features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psds_from_epochs(epochs):\n",
    "    \"\"\"Extracts power spectrum densities from epochs\n",
    "    Returns\n",
    "    --------\n",
    "    psds with associated frequencies calculated with the welch method.\n",
    "    \"\"\"\n",
    "    psds, freqs = psd_welch(epochs, fmin=0.5, fmax=30.)\n",
    "    return psds, freqs\n",
    "\n",
    "get_psds_from_epochs_transformer = FunctionTransformer(get_psds_from_epochs, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Absolute and relative mean power for each band\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_psds(psds_with_freqs, are_relative=False):\n",
    "    \"\"\"EEG power band feature extraction.\n",
    "    Input\n",
    "    -------\n",
    "    psds_with_freqs: tuple which contains\n",
    "            - (nb_epochs, nb_chan=1, nb_freqs) psds amplitudes\n",
    "            - (nb_freqs,) corresponding frequency values\n",
    "            \n",
    "    are_relative: boolean which indicates if the mean band powers\n",
    "        for each subband are relative to the total power or not.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array of shape [n_samples, nb_subband=5]\n",
    "        Transformed data.\n",
    "    \"\"\"\n",
    "    psds = psds_with_freqs[0]\n",
    "    freqs = psds_with_freqs[1]\n",
    "    \n",
    "    if are_relative:\n",
    "        psds /= np.sum(psds, axis=-1, keepdims=True)\n",
    "\n",
    "    X = []\n",
    "    for fmin, fmax in FREQ_BANDS_RANGE.values():\n",
    "        psds_band = psds[:, :, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)\n",
    "        X.append(psds_band.reshape(len(psds), -1))\n",
    "\n",
    "    return np.concatenate(X, axis=1)\n",
    "\n",
    "absolute_mean_psds_transformer = FunctionTransformer(get_mean_psds, validate=False)\n",
    "relative_mean_psds_transformer = FunctionTransformer(lambda psds_with_freq: get_mean_psds(psds_with_freq, are_relative=True), validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Spectral edge frequency difference\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sefd(psd, freqs):\n",
    "    \"\"\"Spectral edge frequency difference\n",
    "    Input\n",
    "    -------\n",
    "    psd: array of the power spectrum density for one epoch\n",
    "    freqs: array of the frequencies\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Difference between the frequencies under which cumulates 95 and 50 percent of the power\n",
    "    \"\"\"\n",
    "    assert len(psd) == len(freqs), \"All PSD value must have a corresponding frequency value\"\n",
    "    \n",
    "    CUMUL_POWER_RATIO = [0.50, 0.95]\n",
    "\n",
    "    total_power = np.sum(psd)\n",
    "    cumul_power = 0\n",
    "\n",
    "    lower_freq = None\n",
    "    upper_freq = None\n",
    "    \n",
    "    for amp, freq in zip(psd, freqs):\n",
    "        cumul_power += amp\n",
    "        if cumul_power >= CUMUL_POWER_RATIO[1] * total_power:\n",
    "            upper_freq = freq\n",
    "            break\n",
    "        elif lower_freq is None and cumul_power >= CUMUL_POWER_RATIO[0] * total_power:\n",
    "            lower_freq = freq\n",
    "\n",
    "    return upper_freq - lower_freq\n",
    "\n",
    "\n",
    "def get_sefd_on_all_epochs(psds_with_freqs):\n",
    "    \"\"\"SEFd on all epochs\n",
    "    \"\"\"\n",
    "    SUBBAND_FREQ_SEFD = [8., 16.]\n",
    "\n",
    "    psds = psds_with_freqs[0].squeeze()\n",
    "    freqs = psds_with_freqs[1]\n",
    "    \n",
    "    psds = psds[:, (freqs >= SUBBAND_FREQ_SEFD[0]) & (freqs < SUBBAND_FREQ_SEFD[1])]\n",
    "    freqs = freqs[(freqs >= SUBBAND_FREQ_SEFD[0]) & (freqs < SUBBAND_FREQ_SEFD[1])]\n",
    "    \n",
    "    return [[get_sefd(one_epoch_psd, freqs)] for one_epoch_psd in psds]\n",
    "\n",
    "sefd_transformer = FunctionTransformer(get_sefd_on_all_epochs, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merging all frequency domain features with `FeatureUnion`\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_FREQUENCY_DOMAIN_FEATURES = 2 * len(FREQ_BANDS_RANGE) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_domain_feature_union = FeatureUnion([\n",
    "    ('absolute_mean_power_band', absolute_mean_psds_transformer),\n",
    "    ('relative_mean_power_band', relative_mean_psds_transformer),\n",
    "    ('sefd', sefd_transformer)\n",
    "], n_jobs=1)\n",
    "\n",
    "frequency_domain_pipeline = Pipeline([\n",
    "    ('get_psds_from_epochs', get_psds_from_epochs_transformer),\n",
    "    ('frequency_domain_features', frequency_domain_feature_union)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Sub-band features\n",
    "___\n",
    "\n",
    "Certain features discriminate more sleep stages when they are calculated only on a particular sub-band. We will provide functions which calculates the value on each sub-band, and then divide the signal before calling these functions.\n",
    "\n",
    "##### a) Mean energy\n",
    "___\n",
    "\n",
    "Mean energy corresponds to $ME = \\frac{1}{N}\\sum_{t=0}^{N} x_t^2$, where N is the epoch length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal_mean_energy(signal):\n",
    "    \"\"\"\n",
    "    signal: array of (nb_sample_per_epoch,)\n",
    "    \"\"\"\n",
    "    return np.sum(signal**2)*1e6\n",
    "\n",
    "mean_energy_transformer = FunctionTransformer(get_transformer(get_signal_mean_energy), validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply 5 IIR filters on all of our epochs in order to calculate time domain features on sub-band epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_per_subband(subband_name: str):\n",
    "    \"\"\"\n",
    "    Constructs a pipeline to extract the specified subband related features.\n",
    "    Output:\n",
    "        sklearn.pipeline.Pipeline object containing all steps to calculate time-domain feature on the specified subband.\n",
    "    \"\"\"\n",
    "    \n",
    "    freq_range = FREQ_BANDS_RANGE[subband_name]\n",
    "    order = FREQ_BANDS_ORDERS[subband_name]\n",
    "    \n",
    "    assert len(freq_range) == 2, \"Frequency range must only have 2 elements: [lower bound frequency, upper bound frequency]\"\n",
    "    \n",
    "    bounds = [freq/NYQUIST_FREQ for freq in freq_range]\n",
    "    b, a = butter(order, bounds, btype='bandpass')\n",
    "    \n",
    "    def filter_epochs_in_specified_subband(epochs):\n",
    "        return epochs.copy().filter(\n",
    "            l_freq=bounds[0],\n",
    "            h_freq=bounds[1],\n",
    "            method='iir',\n",
    "            n_jobs=1,\n",
    "            iir_params = {\n",
    "                'a': a,\n",
    "                'b': b\n",
    "            }, verbose=False)\n",
    "        \n",
    "    return Pipeline([\n",
    "        ('filter', FunctionTransformer(filter_epochs_in_specified_subband, validate=False)),\n",
    "        ('get-values', get_data_from_epochs_transformer),\n",
    "        ('mean-energy', mean_energy_transformer),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_SUBBAND_TIME_DOMAIN_FEATURES = len(FREQ_BANDS_RANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subband_feature_union = FeatureUnion([(\n",
    "        f\"{band_name}-filter\",\n",
    "        get_pipeline_per_subband(band_name)\n",
    "    ) for band_name in FREQ_BANDS_ORDERS.keys()], n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Complete feature extraction pipeline\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_union = FeatureUnion([\n",
    "    ('time_domain', time_domain_pipeline),\n",
    "    ('frequency_domain', frequency_domain_pipeline),\n",
    "    ('subband_time_domain', subband_feature_union)\n",
    "], n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS = range(83)\n",
    "NIGHT_RECORDINGS = [1, 2]\n",
    "NB_OF_CATEGORICAL_FEATURES = 4\n",
    "SUBJECT_IDX = 0\n",
    "\n",
    "subject_file_names = fetch_data(subjects=SUBJECTS, recording=NIGHT_RECORDINGS)\n",
    "\n",
    "psg_file_names = [names[0] for names in subject_file_names]\n",
    "stage_file_names = [names[1] for names in subject_file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def get_eeg_features(raw_data, df_info, recording_index):\n",
    "    features_file = []\n",
    "\n",
    "    for channel in EEG_CHANNELS:\n",
    "        X_file_channel, y_file_channel = preprocess(raw_data.copy(), channel, df_info)\n",
    "        X_features = feature_union.transform(X_file_channel)\n",
    "        features_file.append(X_features)\n",
    "\n",
    "        print(f\"Done extracting {X_features.shape[1]} features on {X_features.shape[0]} epochs for {channel} for file {psg_file_names[recording_index][-16:]}\\n\")\n",
    "        \n",
    "        assert X_features.shape[0] == len(y_file_channel), \"Features and labels must have the same number of epochs\"\n",
    "    \n",
    "    # Only returns y one time, because both channels refer to the same epochs\n",
    "    return np.hstack(tuple(features_file)), y_file_channel \n",
    "\n",
    "def get_categorical_features(df_info, nb_observations):\n",
    "    \"\"\"Returns the categorical feature matrix\n",
    "    Input\n",
    "    -------\n",
    "    df_info: df which contains only one subject night recording informations\n",
    "    nb_observations: corresponds to the number of epochs which will be analyzed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Array of size (nb_epochs,nb_categorical_features), which contains (duplicated) value for all \n",
    "    epochs because it concerns the same subject.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subject index is only used to make train, valid and test set. It is then discarded.\n",
    "    X_categorical = [\n",
    "        df_info['subject'].values[0],\n",
    "        df_info['night'].values[0],\n",
    "        df_info['sex'].values[0],\n",
    "        df_info['AgeCategory'].values[0]\n",
    "    ]\n",
    "    \n",
    "    return np.array(X_categorical*nb_observations).reshape(nb_observations,len(X_categorical))\n",
    "\n",
    "def get_features(recording_index):\n",
    "    \"\"\"Returns the raw features\n",
    "    Input\n",
    "    -------\n",
    "    recording_index: index starting at 0..nb_files-1.\n",
    "        ** It does not corresponds to the file indexes if we don't include the first files in the subjects range. **\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    - features X in a vector of (nb_epochs, nb_features)\n",
    "    - labels y in a vector of (nb_epochs,)\n",
    "    \"\"\"\n",
    "    print(\"Calculating for file #\", recording_index)\n",
    "\n",
    "    df_info = get_recording_info(psg_file_names[recording_index][-16:])\n",
    "    raw_data = fetch_signal(psg_file_names[recording_index], stage_file_names[recording_index])\n",
    "    \n",
    "    try:\n",
    "        X_eeg, y = get_eeg_features(raw_data, df_info, recording_index)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: for file \", psg_file_names[recording_index])\n",
    "        raise e\n",
    "\n",
    "    X_categorical = get_categorical_features(df_info, len(y))        \n",
    "    X = np.append(X_categorical, X_eeg, axis=1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "with Pool(processes=cpu_count()) as pool:\n",
    "    observations = pool.map(get_features, range(len(psg_file_names)))\n",
    "    X, y = zip(*observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 30s per subject (15s per file) to compute our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/x_features.npy\", X)\n",
    "np.save(\"./data/y_observations.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./data/x_features.npy\", allow_pickle=True)\n",
    "y = np.load(\"./data/y_observations.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(X)\n",
    "y = np.hstack(y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_per_chan = [NB_OF_CATEGORICAL_FEATURES, NB_OF_TIME_DOMAIN_FEATURES, NB_OF_FREQUENCY_DOMAIN_FEATURES, NB_OF_SUBBAND_TIME_DOMAIN_FEATURES]\n",
    "nb_features_per_chan = np.sum(feature_per_chan)\n",
    "\n",
    "def get_features_range(nb_features_in_domain, offset):\n",
    "    return list(range(offset,nb_features_in_domain+offset))+list(range(nb_features_per_chan+offset-NB_OF_CATEGORICAL_FEATURES, nb_features_per_chan + nb_features_in_domain+offset-NB_OF_CATEGORICAL_FEATURES))\n",
    "\n",
    "categorical_feature_range = list(range(NB_OF_CATEGORICAL_FEATURES))\n",
    "time_domain_feature_range = get_features_range(NB_OF_TIME_DOMAIN_FEATURES, NB_OF_CATEGORICAL_FEATURES)\n",
    "freq_domain_feature_range = get_features_range(NB_OF_FREQUENCY_DOMAIN_FEATURES, NB_OF_CATEGORICAL_FEATURES + NB_OF_TIME_DOMAIN_FEATURES)\n",
    "subband_domain_feature_range = get_features_range(NB_OF_SUBBAND_TIME_DOMAIN_FEATURES, NB_OF_CATEGORICAL_FEATURES + NB_OF_TIME_DOMAIN_FEATURES+NB_OF_FREQUENCY_DOMAIN_FEATURES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
