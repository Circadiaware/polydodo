{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep stage classification: Random Forest & Hidden Markov Model\n",
    "____\n",
    "\n",
    "This model aims to classify sleep stages based on two EEG channel. We will use the features extracted in the `pipeline.ipynb` notebook as the input to a Random Forest. The output of this model will then be used as the input of a HMM. We will implement our HMM the same as in this paper (Malafeev et al., « Automatic Human Sleep Stage Scoring Using Deep Neural Networks »)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure parent folder is in PYTHONPATH\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (StandardScaler)\n",
    "from sklearn.model_selection import (GridSearchCV, GroupKFold)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix,\n",
    "                             plot_confusion_matrix,\n",
    "                             classification_report,\n",
    "                             f1_score,\n",
    "                             cohen_kappa_score,\n",
    "                             log_loss,\n",
    "                             make_scorer)\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "from constants import (SLEEP_STAGES_VALUES, N_STAGES, EPOCH_DURATION)\n",
    "from model_utils import print_hypnogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position of the subject information and night information in the X matrix\n",
    "SUBJECT_IDX = 0 \n",
    "NIGHT_IDX = 1\n",
    "USE_CONTINUOUS_AGE = False\n",
    "DOWNSIZE_SET = False\n",
    "\n",
    "if USE_CONTINUOUS_AGE:\n",
    "    X_file_name = \"../data/x_features-age-continuous.npy\"\n",
    "    y_file_name = \"../data/y_observations-age-continuous.npy\"\n",
    "else:\n",
    "    X_file_name = \"../data/x_features.npy\"\n",
    "    y_file_name = \"../data/y_observations.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_init = np.load(X_file_name, allow_pickle=True)\n",
    "y_init = np.load(y_file_name, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_init = np.vstack(X_init)\n",
    "y_init = np.hstack(y_init)\n",
    "print(X_init.shape)\n",
    "print(y_init.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of subjects: \", np.unique(X_init[:,SUBJECT_IDX]).shape[0]) # Some subject indexes are skipped, thus total number is below 83 (as we can see in https://physionet.org/content/sleep-edfx/1.0.0/)\n",
    "print(\"Number of nights: \", len(np.unique([f\"{int(x[0])}-{int(x[1])}\" for x in X_init[:,SUBJECT_IDX:NIGHT_IDX+1]])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsizing sets\n",
    "___\n",
    "\n",
    "We will use the same set for all experiments. It includes the first 20 subjects, and excludes the 13th, because it only has one night.\n",
    "\n",
    "The last subject will be put in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNSIZE_SET:\n",
    "    # Filtering to only keep first 20 subjects\n",
    "    X_20 = X_init[np.isin(X_init[:,SUBJECT_IDX], range(20))]\n",
    "    y_20 = y_init[np.isin(X_init[:,SUBJECT_IDX], range(20))]\n",
    "\n",
    "    # Exclude the subject with only one night recording (13th)\n",
    "    MISSING_NIGHT_SUBJECT = 13\n",
    "\n",
    "    X = X_20[X_20[:,SUBJECT_IDX] != MISSING_NIGHT_SUBJECT]\n",
    "    y = y_20[X_20[:,SUBJECT_IDX] != MISSING_NIGHT_SUBJECT]\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "else:\n",
    "    X = X_init\n",
    "    y = y_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of subjects: \", np.unique(X[:,SUBJECT_IDX]).shape[0]) # Some subject indexes are skipped, thus total number is below 83 (as we can see in https://physionet.org/content/sleep-edfx/1.0.0/)\n",
    "print(\"Subjects available: \", np.unique(X[:,SUBJECT_IDX]))\n",
    "print(\"Number of nights: \", len(np.unique([f\"{int(x[0])}-{int(x[1])}\" for x in X[:,SUBJECT_IDX:NIGHT_IDX+1]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, validation and test sets\n",
    "___\n",
    "\n",
    "If we downsize the dataset, the test set will only contain the two nights recording of the last subject (no 19) will be the test set. The rest will be the train and validation sets.\n",
    "\n",
    "If we did not downsize the dataset, we will randomly pick a subject from each age group to be in the test set. Both nights (if there are two) are placed in the test set so that the classifier does not train on any recordings from a subject placed in the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_one_subject(X, subject_test=19):\n",
    "    test_indexes = np.where(X[:,SUBJECT_IDX] == subject_test)[0]\n",
    "    train_indexes = list(set(range(X.shape[0])) - set(test_indexes))\n",
    "\n",
    "    assert X.shape[0] == len(train_indexes)+len(test_indexes), \"Total train and test sets must corresponds to all dataset\"\n",
    "    \n",
    "    X_test = X[test_indexes,:]\n",
    "    y_test = y[test_indexes]\n",
    "    X_train = X[train_indexes,:]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    return X_test, X_train, y_test, y_train\n",
    "\n",
    "def train_test_split_according_to_age(X, subjects_test=None):\n",
    "    AGE_CATEGORY_COL_IDX = 3\n",
    "    SUBJECT_COL_IDX = 0\n",
    "    AGE_GROUPS = [\n",
    "        [0,49],  # 39 recordings\n",
    "        [50,59], # 41 recordings\n",
    "        [60,84], # 41 recordings\n",
    "        [85,110] # 32 recordings\n",
    "    ]\n",
    "    age_categories = np.unique(X[:, AGE_CATEGORY_COL_IDX])\n",
    "    assert subjects_test is None or len(subjects_test) == len(age_categories), \"If subjects are specified, they must be specified for all age groups\"\n",
    "\n",
    "    if subjects_test is None:\n",
    "        unique_subject_with_age = np.array([\n",
    "            (subject, X[observation_idx, AGE_CATEGORY_COL_IDX])\n",
    "            for subject, observation_idx\n",
    "            in zip(*np.unique(X[:,SUBJECT_COL_IDX], return_index=True))])\n",
    "\n",
    "        if USE_CONTINUOUS_AGE:\n",
    "            subjects_test = [\n",
    "                np.random.choice(\n",
    "                    unique_subject_with_age[\n",
    "                        (unique_subject_with_age[:,1] >= age_range[0]) &\n",
    "                        (unique_subject_with_age[:,1] <= age_range[1]), 0])\n",
    "                for age_range in AGE_GROUPS\n",
    "            ]\n",
    "        else:\n",
    "            subjects_test = [\n",
    "                np.random.choice(\n",
    "                    unique_subject_with_age[\n",
    "                        unique_subject_with_age[:,1] == age, 0])\n",
    "                for age in age_categories\n",
    "            ]\n",
    "\n",
    "    print(\"Selected subjects for the test set are: \", subjects_test)\n",
    "    test_indexes = np.where(np.isin(X[:,SUBJECT_IDX], subjects_test))[0]\n",
    "    train_indexes = list(set(range(X.shape[0])) - set(test_indexes))\n",
    "\n",
    "    assert X.shape[0] == len(train_indexes)+len(test_indexes), \"Total train and test sets must corresponds to all dataset\"\n",
    "    \n",
    "    X_test = X[test_indexes,:]\n",
    "    y_test = y[test_indexes]\n",
    "    X_train = X[train_indexes,:]\n",
    "    y_train = y[train_indexes]\n",
    "    \n",
    "    return X_test, X_train, y_test, y_train\n",
    "\n",
    "if DOWNSIZE_SET:\n",
    "    X_test, X_train_valid, y_test, y_train_valid = train_test_split_one_subject(X)\n",
    "else:\n",
    "    X_test, X_train_valid, y_test, y_train_valid = train_test_split_according_to_age(\n",
    "        X , subjects_test=[0.0, 24.0, 49.0, 71.0]\n",
    "    )\n",
    "    \n",
    "print(X_test.shape, X_train_valid.shape, y_test.shape, y_train_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest validation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_KFOLDS = 5\n",
    "NB_CATEGORICAL_FEATURES = 2\n",
    "NB_FEATURES = 48\n",
    "\n",
    "CLASSIFIER_PIPELINE_KEY = 'classifier'\n",
    "\n",
    "def get_random_forest_model():\n",
    "    return Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        (CLASSIFIER_PIPELINE_KEY, RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cross validation, we will use the `GroupKFold` technique. For each fold, we make sure to train and validate on different subjects, to avoid overfitting over subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accuracies = []\n",
    "macro_f1_scores = []\n",
    "weighted_f1_scores = []\n",
    "kappa_agreements = []\n",
    "emission_matrix = np.zeros((N_STAGES,N_STAGES))\n",
    "\n",
    "for train_index, valid_index in GroupKFold(n_splits=5).split(X_train_valid, groups=X_train_valid[:,SUBJECT_IDX]):\n",
    "    # We drop the subject and night indexes\n",
    "    X_train, X_valid = X_train_valid[train_index, 2:], X_train_valid[valid_index, 2:]\n",
    "    y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
    "    \n",
    "    # Scaling features and model training\n",
    "    training_pipeline = get_random_forest_model()\n",
    "    training_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation\n",
    "    y_valid_pred = training_pipeline.predict(X_valid)\n",
    "\n",
    "    print(\"----------------------------- FOLD RESULTS --------------------------------------\\n\")\n",
    "    current_kappa = cohen_kappa_score(y_valid, y_valid_pred)\n",
    "\n",
    "    print(\"TRAIN:\", train_index, \"VALID:\", valid_index, \"\\n\\n\")\n",
    "    print(confusion_matrix(y_valid, y_valid_pred), \"\\n\")\n",
    "    print(classification_report(y_valid, y_valid_pred, target_names=SLEEP_STAGES_VALUES.keys()), \"\\n\")\n",
    "    print(\"Agreement score (Cohen Kappa): \", current_kappa, \"\\n\")\n",
    "    \n",
    "    accuracies.append(round(accuracy_score(y_valid, y_valid_pred),2))\n",
    "    macro_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"macro\"))\n",
    "    weighted_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"weighted\"))\n",
    "    kappa_agreements.append(current_kappa)\n",
    "    \n",
    "    for y_pred, y_true in zip(y_valid_pred, y_valid):\n",
    "        emission_matrix[y_true, y_pred] += 1\n",
    "\n",
    "emission_matrix = emission_matrix / emission_matrix.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean accuracy          : {np.mean(accuracies):0.2f} ± {np.std(accuracies):0.3f}\")\n",
    "print(f\"Mean macro F1-score    : {np.mean(macro_f1_scores):0.2f} ± {np.std(macro_f1_scores):0.3f}\")\n",
    "print(f\"Mean weighted F1-score : {np.mean(weighted_f1_scores):0.2f} ± {np.std(weighted_f1_scores):0.3f}\")\n",
    "print(f\"Mean Kappa's agreement : {np.mean(kappa_agreements):0.2f} ± {np.std(kappa_agreements):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation results\n",
    "___\n",
    "\n",
    "### Random forest hyperparameters\n",
    "___\n",
    "\n",
    "We have fixed the same hyperparameters for the other categories:\n",
    "- `StandardScaler` for all continuous features\n",
    "- Training on all the dataset (83 subjects)\n",
    "- Test set contains the following subjects: `[3.0, 24.0, 55.0, 72.0]`\n",
    "- No postprocessing step\n",
    "- RF with its default hyperparameters\n",
    "\n",
    "#### 1. class_weight: balanced vs none\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    f\"{CLASSIFIER_PIPELINE_KEY}__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "classifier = get_random_forest_model()\n",
    "cross_valid_folds = GroupKFold(n_splits=2).split(X_train_valid, groups=X_train_valid[:,SUBJECT_IDX])\n",
    "\n",
    "search = GridSearchCV(\n",
    "    classifier,\n",
    "    params,\n",
    "    scoring=make_scorer(cohen_kappa_score),\n",
    "    cv=cross_valid_folds,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "search.fit(X_train_valid[:,2:], y_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for idx, rank in enumerate(search.cv_results_['rank_test_score']):\n",
    "    current_param = search.cv_results_['params'][idx]\n",
    "    score_mean = search.cv_results_['mean_test_score'][idx]\n",
    "    score_uncertainty = search.cv_results_['std_test_score'][idx]\n",
    "    print(f\"{rank}. Parameter {current_param} has a score of {score_mean:0.4f} ± {score_uncertainty:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|  Value      |  Score          |\n",
    "|-------------|-----------------|\n",
    "| `None`      | 0.6153 ± 0.003  |\n",
    "|  `balanced` |  0.6114 ± 0.002 |\n",
    "\n",
    "The chosen value for `class_weight` is then `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest training and testing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_pipeline = get_random_forest_model()\n",
    "\n",
    "testing_pipeline.fit(X_train_valid[:, 2:], y_train_valid);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = testing_pipeline.predict(X_test[:,2:])\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Model Markov\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hmm_matrices(y, subject_night):\n",
    "    transition_matrix = np.zeros((N_STAGES,N_STAGES))\n",
    "    start_matrix = np.zeros((N_STAGES))\n",
    "\n",
    "    for night in groupby(zip(y, subject_night), key=lambda x: f\"subject{int(x[1][0])}-night{int(x[1][1])}\"):\n",
    "        print(f\"Computing file: {night[0]}\")\n",
    "        current_y = np.array([x[0] for x in night[1]])\n",
    "        start_matrix[current_y[0]] += 1\n",
    "\n",
    "        for transition in zip(current_y[:-1], current_y[1:]):\n",
    "            transition_matrix[transition[0], transition[1]] += 1\n",
    "            \n",
    "    transition_matrix = transition_matrix/transition_matrix.sum(axis=1, keepdims=True)\n",
    "    start_matrix = start_matrix/start_matrix.sum()\n",
    "    \n",
    "    return transition_matrix, start_matrix\n",
    "    \n",
    "transition_matrix, start_matrix = compute_hmm_matrices(y_train_valid, X_train_valid[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_model = MultinomialHMM(n_components=N_STAGES)\n",
    "\n",
    "hmm_model.transmat_ = transition_matrix\n",
    "hmm_model.startprob_ = start_matrix\n",
    "hmm_model.emissionprob_ = emission_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hmm_pred = hmm_model.predict(y_test_pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_hmm_pred))\n",
    "\n",
    "print(classification_report(y_test, y_hmm_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_hmm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test subjects are subjects: \", np.unique(X_test[:,0]))\n",
    "print(\"BEFORE HMM\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "for test_subject in np.unique(X_test[:,0]):\n",
    "    test_subject_indexes = [idx for idx, elem in enumerate(X_test) if elem[0] == test_subject]\n",
    "    \n",
    "    for night_idx in np.unique(X_test[test_subject_indexes,1]):\n",
    "        test_night_subject_indexes = [\n",
    "            idx for idx, elem in enumerate(X_test)\n",
    "            if elem[0] == test_subject and elem[1] == night_idx]\n",
    "        hypnograms = [\n",
    "            y_test[test_night_subject_indexes],\n",
    "            y_test_pred[test_night_subject_indexes]\n",
    "        ]\n",
    "        \n",
    "        print_hypnogram(hypnograms,\n",
    "                        labels=[\"scored\", \"predicted\"],\n",
    "                        subject=test_subject,\n",
    "                        night=night_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test subjects are subjects: \", np.unique(X_test[:,0]))\n",
    "print(\"AFTER HMM\")\n",
    "\n",
    "for test_subject in np.unique(X_test[:,0]):\n",
    "    test_subject_indexes = [idx for idx, elem in enumerate(X_test) if elem[0] == test_subject]\n",
    "    \n",
    "    for night_idx in np.unique(X_test[test_subject_indexes,1]):\n",
    "        test_night_subject_indexes = [\n",
    "            idx for idx, elem in enumerate(X_test)\n",
    "            if elem[0] == test_subject and elem[1] == night_idx]\n",
    "        hypnograms = [\n",
    "            y_test[test_night_subject_indexes],\n",
    "            y_hmm_pred[test_night_subject_indexes]\n",
    "        ]\n",
    "        \n",
    "        print_hypnogram(hypnograms,\n",
    "                        labels=[\"scored\", \"predicted with HMM\"],\n",
    "                        subject=test_subject,\n",
    "                        night=night_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median filter\n",
    "___\n",
    "\n",
    "In order to compare the HMM postprocessing step, we will apply a median filter to the output of the RF.\n",
    "\n",
    "We apply a median filter with a 3 element sized kernel. It is applied to each nights sleep seperatly. We do this because short transitions are not common in sleep patterns:\n",
    "\n",
    "> The final stage includes median filtration of short-term transitions. It is well known that short-term transitions in human sleep are impossible. Short-term jumps in hypnogram are evidence of transitory stage. Averaging for 2-3 min allows the curve structure to be smoothed and sleep structure to be resolved. \n",
    "\n",
    "Source: Doroshenkov, L. G., V. A. Konyshev, et S. V. Selishchev. « Classification of Human Sleep Stages Based on EEG Processing Using Hidden Markov Models ». Biomedical Engineering 41, nᵒ 1 (janvier 2007): 25‑28. https://doi.org/10.1007/s10527-007-0006-5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE=3\n",
    "y_medfilt_pred = np.zeros(y_test.shape[0])\n",
    "\n",
    "for test_subject in np.unique(X_test[:,0]):\n",
    "    test_subject_indexes = [idx for idx, elem in enumerate(X_test) if elem[0] == test_subject]\n",
    "    \n",
    "    for night_idx in np.unique(X_test[test_subject_indexes,1]):\n",
    "        test_night_subject_indexes = [\n",
    "            idx for idx, elem in enumerate(X_test)\n",
    "            if elem[0] == test_subject and elem[1] == night_idx]\n",
    "\n",
    "        y_medfilt_pred[test_night_subject_indexes] = medfilt(y_test_pred[test_night_subject_indexes], kernel_size=KERNEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_medfilt_pred))\n",
    "\n",
    "print(classification_report(y_test, y_medfilt_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_medfilt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "print(\"Test subjects are subjects: \", np.unique(X_test[:,0]))\n",
    "\n",
    "for test_subject in np.unique(X_test[:,0]):\n",
    "    test_subject_indexes = [idx for idx, elem in enumerate(X_test) if elem[0] == test_subject]\n",
    "    \n",
    "    for night_idx in np.unique(X_test[test_subject_indexes,1]):\n",
    "        test_night_subject_indexes = [\n",
    "            idx for idx, elem in enumerate(X_test)\n",
    "            if elem[0] == test_subject and elem[1] == night_idx]\n",
    "        \n",
    "        hypnograms = [\n",
    "            y_test[test_night_subject_indexes],\n",
    "            y_medfilt_pred[test_night_subject_indexes]\n",
    "        ]\n",
    "        \n",
    "        print_hypnogram(hypnograms,\n",
    "                        labels=[\"scored\", \"predicted with median filter\"],\n",
    "                        subject=test_subject,\n",
    "                        night=night_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving trained model\n",
    "___\n",
    "\n",
    "We save the trained model with the postprocessing step, HMM. We will save only the matrix that define it. We do not need to persist the median filter postprocessing step, because it is stateless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_DIR = \"../trained_model\"\n",
    "\n",
    "if not os.path.exists(SAVED_DIR):\n",
    "    os.mkdir(SAVED_DIR);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CONTINUOUS_AGE: \n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_RF_continous_age.joblib\")\n",
    "else:\n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_RF.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{SAVED_DIR}/HMM_transmat.npy\", hmm_model.transmat_)\n",
    "np.save(f\"{SAVED_DIR}/HMM_startprob.npy\", hmm_model.startprob_)\n",
    "np.save(f\"{SAVED_DIR}/HMM_emissionprob.npy\", hmm_model.emissionprob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('py3': conda)",
   "language": "python",
   "name": "python36864bitpy3conda60d5576ae6834cf0a5dc3773043eb4d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
