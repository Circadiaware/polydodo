{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naïve Bayes\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure parent folder is in PYTHONPATH\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "     confusion_matrix,\n",
    "     classification_report,\n",
    "     f1_score,\n",
    "     cohen_kappa_score,\n",
    "     make_scorer,\n",
    ")\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import (SelectKBest, f_classif)\n",
    "\n",
    "from constants import (\n",
    "    SLEEP_STAGES_VALUES,\n",
    "    N_STAGES,\n",
    "    EPOCH_DURATION,\n",
    ")\n",
    "from model_utils import (\n",
    "    print_hypnogram,\n",
    "    train_test_split_one_subject,\n",
    "    train_test_split_according_to_age,\n",
    "    evaluate_hyperparams_grid,\n",
    "    print_results_cv,\n",
    "    print_results_cv_scores,\n",
    "    get_pipeline,\n",
    "    print_hyperparam_tuning_results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# position of the subject information and night information in the X matrix\n",
    "SUBJECT_IDX = 0 \n",
    "NIGHT_IDX = 1\n",
    "USE_CONTINUOUS_AGE = False\n",
    "DOWNSIZE_SET = False\n",
    "TEST_SET_SUBJECTS = [0.0, 24.0, 49.0, 71.0]\n",
    "\n",
    "if USE_CONTINUOUS_AGE:\n",
    "    X_file_name = \"../data/x_features-age-continuous.npy\"\n",
    "    y_file_name = \"../data/y_observations-age-continuous.npy\"\n",
    "else:\n",
    "    X_file_name = \"../data/x_features.npy\"\n",
    "    y_file_name = \"../data/y_observations.npy\"\n",
    "    \n",
    "X_init = np.load(X_file_name, allow_pickle=True)\n",
    "y_init = np.load(y_file_name, allow_pickle=True)\n",
    "\n",
    "X_init = np.vstack(X_init)\n",
    "y_init = np.hstack(y_init)\n",
    "\n",
    "print(X_init.shape)\n",
    "print(y_init.shape)\n",
    "print(\"Number of subjects: \", np.unique(X_init[:,SUBJECT_IDX]).shape[0]) # Some subject indexes are skipped, thus total number is below 83 (as we can see in https://physionet.org/content/sleep-edfx/1.0.0/)\n",
    "print(\"Number of nights: \", len(np.unique([f\"{int(x[0])}-{int(x[1])}\" for x in X_init[:,SUBJECT_IDX:NIGHT_IDX+1]])))\n",
    "print(\"Subjects available: \", np.unique(X_init[:,SUBJECT_IDX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train_valid, y_test, y_train_valid = train_test_split_according_to_age(\n",
    "    X_init,\n",
    "    y_init,\n",
    "    use_continuous_age=USE_CONTINUOUS_AGE,\n",
    "    subjects_test=TEST_SET_SUBJECTS)\n",
    "    \n",
    "print(X_test.shape, X_train_valid.shape, y_test.shape, y_train_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB validation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_KFOLDS = 5\n",
    "NB_CATEGORICAL_FEATURES = 2\n",
    "NB_FEATURES = 48\n",
    "CLASSIFIER_PIPELINE_KEY = 'classifier'\n",
    "RANDOM_STATE = 42 \n",
    "\n",
    "def get_cv_iterator(n_splits=2):\n",
    "    return GroupKFold(n_splits=n_splits).split(\n",
    "        X_train_valid, groups=X_train_valid[:,SUBJECT_IDX]\n",
    "    )\n",
    "    \n",
    "def cross_validate_with_confusion_matrix(pipeline, n_fold):\n",
    "    accuracies = []\n",
    "    macro_f1_scores = []\n",
    "    weighted_f1_scores = []\n",
    "    kappa_agreements = []\n",
    "\n",
    "    for train_index, valid_index in get_cv_iterator(n_splits=n_fold):\n",
    "        # We drop the subject and night indexes\n",
    "        X_train, X_valid = X_train_valid[train_index, 2:], X_train_valid[valid_index, 2:]\n",
    "        y_train, y_valid = y_train_valid[train_index], y_train_valid[valid_index]\n",
    "\n",
    "        # Scaling features and model training\n",
    "        training_pipeline = pipeline\n",
    "        training_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Validation\n",
    "        y_valid_pred = training_pipeline.predict(X_valid)\n",
    "\n",
    "        print(\"----------------------------- FOLD RESULTS --------------------------------------\\n\")\n",
    "        current_kappa = cohen_kappa_score(y_valid, y_valid_pred)\n",
    "\n",
    "        print(\"TRAIN:\", train_index, \"VALID:\", valid_index, \"\\n\\n\")\n",
    "        print(confusion_matrix(y_valid, y_valid_pred), \"\\n\")\n",
    "        print(classification_report(y_valid, y_valid_pred, target_names=SLEEP_STAGES_VALUES.keys()), \"\\n\")\n",
    "        print(\"Agreement score (Cohen Kappa): \", current_kappa, \"\\n\")\n",
    "\n",
    "        accuracies.append(round(accuracy_score(y_valid, y_valid_pred),2))\n",
    "        macro_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"macro\"))\n",
    "        weighted_f1_scores.append(f1_score(y_valid, y_valid_pred, average=\"weighted\"))\n",
    "        kappa_agreements.append(current_kappa)\n",
    "\n",
    "    print_results_cv(accuracies, macro_f1_scores, weighted_f1_scores, kappa_agreements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cross_validate_with_confusion_matrix(get_pipeline(\n",
    "    classifier=GaussianNB()\n",
    "), n_fold=NB_KFOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Agreement score (Cohen Kappa):  0.40234998625108576 \n",
    "\n",
    "Mean accuracy          : 0.55 ± 0.037\n",
    "Mean macro F1-score    : 0.51 ± 0.039\n",
    "Mean weighted F1-score : 0.56 ± 0.029\n",
    "Mean Kappa's agreement : 0.42 ± 0.047\n",
    "CPU times: user 3.13 s, sys: 1.08 s, total: 4.21 s\n",
    "Wall time: 5.75 s\n",
    "```\n",
    "\n",
    "## Dimensionality reduction\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_with_dim_reduction(dim_reduction, pipeline=None):\n",
    "    if pipeline is None:\n",
    "        pipeline = get_pipeline(\n",
    "            classifier=GaussianNB(),\n",
    "            dimension_reduction=dim_reduction\n",
    "        )\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        estimator=pipeline,\n",
    "        X=X_train_valid,\n",
    "        y=y_train_valid,\n",
    "        groups=X_train_valid[:,SUBJECT_IDX],\n",
    "        scoring={\n",
    "            \"agreement\": make_scorer(cohen_kappa_score),\n",
    "            \"accuracy\": 'accuracy',\n",
    "            \"f1-score-macro\": 'f1_macro',\n",
    "            \"f1-score-weighted\": 'f1_weighted',\n",
    "        },\n",
    "        cv=get_cv_iterator(n_splits=5),\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print_results_cv_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cross_validate_with_dim_reduction(LinearDiscriminantAnalysis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_with_dim_reduction(PCA(n_components=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_with_dim_reduction(PCA(n_components=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_with_dim_reduction(PCA(n_components=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA gave the best results:\n",
    "\n",
    "```\n",
    "Mean accuracy          : 0.68 ± 0.027\n",
    "Mean macro F1-score    : 0.60 ± 0.023\n",
    "Mean weighted F1-score : 0.66 ± 0.025\n",
    "Mean Kappa's agreement : 0.55 ± 0.037\n",
    "CPU times: user 112 ms, sys: 137 ms, total: 249 ms\n",
    "Wall time: 14 s\n",
    "```\n",
    "\n",
    "## Feature selection\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_with_dim_reduction(None, pipeline=\n",
    "  Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=15)),\n",
    "        ('dimension_reduction', LinearDiscriminantAnalysis()),\n",
    "        (CLASSIFIER_PIPELINE_KEY, GaussianNB())\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_hyperparams_grid(\n",
    "    params={\n",
    "        f\"feature_selection__k\": np.random.randint(low=0, high=48, size=10),\n",
    "    },\n",
    "    estimator=Pipeline([\n",
    "        ('scaling', ColumnTransformer([\n",
    "            ('pass-through-categorical', 'passthrough', list(range(NB_CATEGORICAL_FEATURES))),\n",
    "            ('scaling-continuous', StandardScaler(copy=False), list(range(NB_CATEGORICAL_FEATURES,NB_FEATURES)))\n",
    "        ])),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=15)),\n",
    "        ('dimension_reduction', LinearDiscriminantAnalysis()),\n",
    "        (CLASSIFIER_PIPELINE_KEY, GaussianNB())\n",
    "    ]),\n",
    "    X=X_train_valid,\n",
    "    y=y_train_valid,\n",
    "    cv=get_cv_iterator(n_splits=2),\n",
    "    use_randomized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. Parameter {'feature_selection__k': 46} has a score of 0.5633 ± 0.013\n",
    "2. Parameter {'feature_selection__k': 45} has a score of 0.5628 ± 0.013\n",
    "3. Parameter {'feature_selection__k': 43} has a score of 0.5624 ± 0.013\n",
    "4. Parameter {'feature_selection__k': 25} has a score of 0.5368 ± 0.015\n",
    "5. Parameter {'feature_selection__k': 24} has a score of 0.5357 ± 0.014\n",
    "6. Parameter {'feature_selection__k': 17} has a score of 0.5090 ± 0.009\n",
    "7. Parameter {'feature_selection__k': 12} has a score of 0.4797 ± 0.033\n",
    "8. Parameter {'feature_selection__k': 6} has a score of 0.4361 ± 0.013\n",
    "9. Parameter {'feature_selection__k': 3} has a score of 0.3439 ± 0.001\n",
    "10. Parameter {'feature_selection__k': 0} has a score of nan ± nan\n",
    "CPU times: user 3.28 s, sys: 779 ms, total: 4.06 s\n",
    "Wall time: 28.2 s\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Best combination is to not use feature selection, and to use LDA.\n",
    "\n",
    "## Model testing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "testing_pipeline = get_pipeline(\n",
    "    classifier=GaussianNB(),\n",
    "    dimension_reduction=LinearDiscriminantAnalysis()\n",
    ")\n",
    "\n",
    "testing_pipeline.fit(X_train_valid[:, 2:], y_train_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = testing_pipeline.predict(X_test[:,2:])\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=SLEEP_STAGES_VALUES.keys()))\n",
    "\n",
    "print(\"Agreement score (Cohen Kappa): \", cohen_kappa_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results\n",
    "___\n",
    "\n",
    "#### 1) With default parameters\n",
    "____\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.79      0.44      0.57      1624\n",
    "          N1       0.25      0.30      0.28       983\n",
    "          N2       0.79      0.67      0.72      3603\n",
    "          N3       0.42      0.99      0.59       611\n",
    "         REM       0.53      0.63      0.58      1302\n",
    "\n",
    "    accuracy                           0.60      8123\n",
    "   macro avg       0.56      0.61      0.55      8123\n",
    "weighted avg       0.65      0.60      0.60      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.4626294533458143\n",
    "```\n",
    "\n",
    "#### 2) With LDA\n",
    "___\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.84      0.87      0.85      1624\n",
    "          N1       0.44      0.22      0.30       983\n",
    "          N2       0.81      0.88      0.84      3603\n",
    "          N3       0.71      0.89      0.79       611\n",
    "         REM       0.64      0.61      0.63      1302\n",
    "\n",
    "    accuracy                           0.76      8123\n",
    "   macro avg       0.69      0.69      0.68      8123\n",
    "weighted avg       0.73      0.76      0.74      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.6537897956170273\n",
    "\n",
    "```\n",
    "#### 3) With LDA + feature selection\n",
    "___\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           W       0.84      0.82      0.83      1624\n",
    "          N1       0.40      0.11      0.17       983\n",
    "          N2       0.81      0.86      0.83      3603\n",
    "          N3       0.73      0.84      0.78       611\n",
    "         REM       0.48      0.64      0.55      1302\n",
    "\n",
    "    accuracy                           0.72      8123\n",
    "   macro avg       0.65      0.65      0.63      8123\n",
    "weighted avg       0.71      0.72      0.70      8123\n",
    "\n",
    "Agreement score (Cohen Kappa):  0.6085186109496423\n",
    "```\n",
    "\n",
    "## Saving trained model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_DIR = \"../trained_model\"\n",
    "\n",
    "if not os.path.exists(SAVED_DIR):\n",
    "    os.mkdir(SAVED_DIR);\n",
    "\n",
    "if USE_CONTINUOUS_AGE: \n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_gaussiannb_age_continuous.joblib\")\n",
    "else:\n",
    "    joblib.dump(testing_pipeline, f\"{SAVED_DIR}/classifier_gaussiannb.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('py3': conda)",
   "language": "python",
   "name": "python36864bitpy3conda60d5576ae6834cf0a5dc3773043eb4d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
